{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d08c2eda",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-10-18 15:03:52.873015: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-10-18 15:03:52.909750: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2025-10-18 15:03:54.400307: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ddc75531",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import mixed_precision\n",
    "mixed_precision.set_global_policy('mixed_float16')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "39df25df",
   "metadata": {},
   "outputs": [],
   "source": [
    "def vgg_block(num_conv, num_channels):\n",
    "    blk = tf.keras.models.Sequential()\n",
    "    for i in range(num_conv):\n",
    "        blk.add(tf.keras.layers.Conv2D(num_channels, kernel_size=3, padding='same', activation='relu'))\n",
    "    blk.add(tf.keras.layers.MaxPool2D(pool_size=2, strides=2))\n",
    "    return blk\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d4b98bae",
   "metadata": {},
   "outputs": [],
   "source": [
    "class VGG(tf.keras.Model):\n",
    "    def __init__(self, arch, num_classes=10):\n",
    "        super().__init__()\n",
    "        self.arch = arch\n",
    "        self.num_classes= num_classes\n",
    "        self.net = tf.keras.models.Sequential()\n",
    "        for (num_conv, num_channels) in arch:\n",
    "            self.net.add(vgg_block(num_conv, num_channels))\n",
    "        self.net.add(\n",
    "            tf.keras.models.Sequential([\n",
    "                tf.keras.layers.Flatten(),\n",
    "                tf.keras.layers.Dense(4096, activation='relu'),\n",
    "                tf.keras.layers.Dropout(0.5),\n",
    "                tf.keras.layers.Dense(4096, activation='relu'),\n",
    "                tf.keras.layers.Dropout(0.5),\n",
    "                tf.keras.layers.Dense(10)\n",
    "            ]))\n",
    "    def call(self, x):\n",
    "        return self.net(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68f41e56",
   "metadata": {},
   "source": [
    "The original VGG network had five convolutional blocks, among which the first two have one convolutional layer each and the latter three contain two convolutional layers each. The first block has 64 output channels and each subsequent block doubles the number of output channels, until that number reaches 512. Since this network uses eight convolutional layers and three fully connected layers, it is often called VGG-11."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2cf9f3dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1760792642.064974   28969 gpu_device.cc:2020] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 2131 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3050 Ti Laptop GPU, pci bus id: 0000:01:00.0, compute capability: 8.6\n"
     ]
    }
   ],
   "source": [
    "#vgg_11 = VGG(arch=((1,64), (1,128), (2,256), (2,512), (2,512))) the original vgg\n",
    "vgg_mini = VGG(arch=((1, 16), (1, 32), (2, 64), (2, 128), (2, 128))) #using a small network due to computational constraint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "83e3db48",
   "metadata": {},
   "outputs": [],
   "source": [
    "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.fashion_mnist.load_data()\n",
    "\n",
    "def preprocess(image, label):\n",
    "    image = tf.cast(image, tf.float16) / 255.0\n",
    "    image = tf.expand_dims(image, axis=-1)\n",
    "    image = tf.image.resize(image, [224, 224])\n",
    "    return image, label\n",
    "\n",
    "batch_size = 32\n",
    "\n",
    "train_ds = tf.data.Dataset.from_tensor_slices((x_train, y_train))\n",
    "train_ds = train_ds.map(preprocess) \\\n",
    "                   .shuffle(buffer_size=1024) \\\n",
    "                   .batch(batch_size) \\\n",
    "                   .prefetch(tf.data.AUTOTUNE)\n",
    "\n",
    "test_ds = tf.data.Dataset.from_tensor_slices((x_test, y_test))\n",
    "test_ds = test_ds.map(preprocess) \\\n",
    "                   .shuffle(buffer_size=1024) \\\n",
    "                   .batch(batch_size) \\\n",
    "                   .prefetch(tf.data.AUTOTUNE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4ff376eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-10-18 15:04:07.571070: E tensorflow/core/util/util.cc:131] oneDNN supports DT_HALF only on platforms with AVX-512. Falling back to the default Eigen-based implementation if present.\n",
      "2025-10-18 15:04:07.638180: I external/local_xla/xla/service/service.cc:163] XLA service 0x7fbe20003630 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "2025-10-18 15:04:07.638206: I external/local_xla/xla/service/service.cc:171]   StreamExecutor device (0): NVIDIA GeForce RTX 3050 Ti Laptop GPU, Compute Capability 8.6\n",
      "2025-10-18 15:04:07.655733: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:269] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "2025-10-18 15:04:07.876516: I external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:473] Loaded cuDNN version 91301\n",
      "2025-10-18 15:04:07.913300: I external/local_xla/xla/service/gpu/autotuning/dot_search_space.cc:208] All configs were filtered out because none of them sufficiently match the hints. Maybe the hints set does not contain a good representative set of valid configs? Working around this by using the full hints set instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m   5/1875\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m57s\u001b[0m 31ms/step - loss: 2.3026  "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1760792659.977438   29036 device_compiler.h:196] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m66s\u001b[0m 28ms/step - loss: 0.7055\n",
      "Epoch 2/10\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m54s\u001b[0m 29ms/step - loss: 0.3443\n",
      "Epoch 3/10\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m54s\u001b[0m 29ms/step - loss: 0.2802\n",
      "Epoch 4/10\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m54s\u001b[0m 29ms/step - loss: 0.2368\n",
      "Epoch 5/10\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m54s\u001b[0m 29ms/step - loss: 0.1997\n",
      "Epoch 6/10\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m54s\u001b[0m 29ms/step - loss: 0.1638\n",
      "Epoch 7/10\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m54s\u001b[0m 29ms/step - loss: 0.1312\n",
      "Epoch 8/10\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m54s\u001b[0m 29ms/step - loss: 0.1032\n",
      "Epoch 9/10\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m54s\u001b[0m 29ms/step - loss: 0.0776\n",
      "Epoch 10/10\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m54s\u001b[0m 29ms/step - loss: 0.0627\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x7fbf4f3de0f0>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vgg_mini.compile(optimizer='sgd', loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True))\n",
    "vgg_mini.fit(train_ds ,epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "57aa0fe6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-10-18 15:14:14.934986: I external/local_xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_180', 4 bytes spill stores, 4 bytes spill loads\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 14ms/step - loss: 0.3805\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.3804929852485657"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vgg_mini.evaluate(test_ds)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b7f2059",
   "metadata": {},
   "source": [
    "Manual training of VGG11 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f224b496",
   "metadata": {},
   "outputs": [],
   "source": [
    "vgg_mini = VGG(arch=((1, 16), (1, 32), (2, 64), (2, 128), (2, 128)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1cd760b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_accuracy = tf.keras.metrics.SparseCategoricalAccuracy()\n",
    "\n",
    "loss_fn = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)\n",
    "optimizer = tf.keras.optimizers.SGD(learning_rate=0.01)\n",
    "@tf.function\n",
    "def train_step(images, labels):\n",
    "    with tf.GradientTape() as tape:\n",
    "        predictions = vgg_mini(images, training=True)\n",
    "        loss = loss_fn(labels, predictions)\n",
    "    gradients = tape.gradient(loss, vgg_mini.trainable_variables)\n",
    "    optimizer.apply_gradients(zip(gradients, vgg_mini.trainable_variables))\n",
    "    accuracy = train_accuracy(labels, predictions)\n",
    "    return loss, accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "de6613e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-10-18 15:17:28.994236: I tensorflow/core/framework/local_rendezvous.cc:407] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Training Loss: 0.8174\n",
      "  Training Accuracy: 0.5345\n",
      "Epoch 2/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-10-18 15:18:30.779642: I tensorflow/core/framework/local_rendezvous.cc:407] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Training Loss: 0.4055\n",
      "  Training Accuracy: 0.7468\n",
      "Epoch 3/10\n",
      "  Training Loss: 0.3347\n",
      "  Training Accuracy: 0.7964\n",
      "Epoch 4/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-10-18 15:20:34.876069: I tensorflow/core/framework/local_rendezvous.cc:407] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Training Loss: 0.2933\n",
      "  Training Accuracy: 0.8222\n",
      "Epoch 5/10\n",
      "  Training Loss: 0.2653\n",
      "  Training Accuracy: 0.8394\n",
      "Epoch 6/10\n",
      "  Training Loss: 0.2413\n",
      "  Training Accuracy: 0.8518\n",
      "Epoch 7/10\n",
      "  Training Loss: 0.2245\n",
      "  Training Accuracy: 0.8616\n",
      "Epoch 8/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-10-18 15:24:42.452572: I tensorflow/core/framework/local_rendezvous.cc:407] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Training Loss: 0.2072\n",
      "  Training Accuracy: 0.8695\n",
      "Epoch 9/10\n",
      "  Training Loss: 0.1931\n",
      "  Training Accuracy: 0.8761\n",
      "Epoch 10/10\n",
      "  Training Loss: 0.1768\n",
      "  Training Accuracy: 0.8820\n"
     ]
    }
   ],
   "source": [
    "epochs = 10\n",
    "for epoch in range(epochs):\n",
    "    print(f\"Epoch {epoch+1}/{epochs}\")\n",
    "    total_loss = 0.0\n",
    "    total_acc = 0.0\n",
    "    num_batches = 0\n",
    "    for step,  (x_batch_train, y_batch_train) in enumerate(train_ds):\n",
    "        step = train_step(x_batch_train, y_batch_train)\n",
    "        total_loss += step[0].numpy()\n",
    "        total_acc += step[1].numpy()\n",
    "        num_batches += 1\n",
    "\n",
    "    avg_loss = total_loss / num_batches\n",
    "    avg_acc = total_acc / num_batches\n",
    "    print(f\"  Training Loss: {avg_loss:.4f}\")\n",
    "    print(f\"  Training Accuracy: {avg_acc:.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ai",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
